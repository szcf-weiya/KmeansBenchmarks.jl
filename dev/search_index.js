var documenterSearchIndex = {"docs":
[{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"EditURL = \"../../benchmarks/benchmarks.jl\"","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"using KmeansBenchmarks\nusing Plots\nusing StatsPlots\nusing DataFrames\n\nplotly()","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"repeat two times","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"nrep = 10\nres = [benchmark(arr_data, arr_methods) for _ in 1:nrep]\n\ndf = DataFrame(hcat(repeat(repeat(collect(keys(arr_data)), inner=length(arr_methods)), outer = nrep),\n                repeat(repeat(collect(keys(arr_methods)), outer=length(arr_data)), outer = nrep),\n                vcat([vcat(r...) for r in res]...)), [\"data\", \"method\", \"Acc\", \"BSS/TSS\", \"Time\"]);\nnothing #hide","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"display the first element","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"df1 = DataFrame(hcat(repeat(collect(keys(arr_data)), inner=length(arr_methods)),\n                repeat(collect(keys(arr_methods)), outer=length(arr_data)),\n                vcat(res[1]...)), [\"data\", \"method\", \"Acc\", \"BSS/TSS\", \"Time\"])","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"Calculate the accuracy by comparing the true clustering label and the predicted label","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"groupedboxplot([z[end-4:end] for z in string.(df[:, :data])], df[:, :Acc],\n        group = string.(df[:, :method]), legend = :outerbottomright,\n        size = (1600, 800),\n        xlab = \"signal strength\", ylab = \"accuracy\",\n        title = \"Gaussian (n = 1000, p = 2000)\")","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"Also the ratio of BSS/TSS","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"groupedboxplot([z[end-4:end] for z in string.(df[:, :data])], df[:, \"BSS/TSS\"],\n        group = string.(df[:, :method]), legend = :outerbottomright,\n        size = (1600, 800),\n        xlab = \"signal strength\", ylab = \"BSS/TSS\",\n        title = \"Gaussian (n = 1000, p = 2000)\")","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"And the running time","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"groupedboxplot([z[end-4:end] for z in string.(df[:, :data])], df[:, \"Time\"],\n        group = string.(df[:, :method]), legend = :outerbottomright,\n        size = (1600, 800),\n        xlab = \"signal strength\", ylab = \"Time\",\n        title = \"Gaussian (n = 1000, p = 2000)\")","category":"page"},{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Modules = [KmeansBenchmarks]\nOrder = [:type, :function]","category":"page"},{"location":"api/#KmeansBenchmarks.benchmark-Tuple{NamedTuple, NamedTuple}","page":"API","title":"KmeansBenchmarks.benchmark","text":"benchmark(arr_data::NamedTuple, arr_methods::NamedTuple)\n\nRun the benchmark experiments for all methods in arr_methods on each dataset in arr_data.\n\n\n\n\n\n","category":"method"},{"location":"#Kmeans-Benchmarks","page":"Home","title":"Kmeans Benchmarks","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Clustering is a cornerstone of unsupervised machine learning, with the k-means algorithm standing as one of the most widely used methods for partitioning data into coherent groups. Its simplicity, interpretability, and adaptability have made it a staple in fields ranging from customer segmentation to bioinformatics. However, the performance and results of k-means can vary significantly depending on the implementation choices made by practitioners, including the software ecosystem (e.g., R, Julia, Python), the algorithmic variants employed (e.g., Lloyd’s algorithm, Hartigan-Wong, or scalable approximations like Mini-Batch k-means), and the initialization strategies (e.g., random seeding, k-means++, or density-based initialization). These choices impact not only computational efficiency but also the quality and stability of the resulting clusters.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This project seeks to systematically benchmark and compare k-means implementations across the following aspects:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Software ecosystem: R (e.g., stats, ClusterR) vs Julia (e.g., Clustering)\nAlgorithm variants: Variants like Lloyd’s, Hartigan-Wong\nInitialization: Random seeding, k-means++","category":"page"},{"location":"","page":"Home","title":"Home","text":"We evaluate the performance from three main metrics:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Clustering accuracy\nRatio of the Between-sum-of-squares / Total-sum-of-squares\nComputational time","category":"page"},{"location":"","page":"Home","title":"Home","text":"This work aims to provide actionable insights for researchers and practitioners in selecting optimal k-means configurations tailored to their data size, dimensionality, and domain requirements. ","category":"page"}]
}
