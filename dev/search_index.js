var documenterSearchIndex = {"docs":
[{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"EditURL = \"../../benchmarks/benchmarks.jl\"","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"using KmeansBenchmarks\nusing Plots\nusing StatsPlots\nusing DataFrames\n\nplotly()","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"repeat two times","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"nrep = 2\nres = [benchmark(arr_data, arr_methods) for _ in 1:nrep]\n\ndf = DataFrame(hcat(repeat(repeat(collect(keys(arr_data)), inner=length(arr_methods)), outer = nrep),\n                repeat(repeat(collect(keys(arr_methods)), outer=length(arr_data)), outer = nrep),\n                vcat([vcat(r...) for r in res]...)), [\"data\", \"method\", \"Acc\", \"BSS/TSS\", \"Time\"]);\nnothing #hide","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"display the first element","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"df1 = DataFrame(hcat(repeat(collect(keys(arr_data)), inner=length(arr_methods)),\n                repeat(collect(keys(arr_methods)), outer=length(arr_data)),\n                vcat(res[1]...)), [\"data\", \"method\", \"Acc\", \"BSS/TSS\", \"Time\"])","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"Calculate the accuracy by comparing the true clustering label and the predicted label","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"groupedboxplot([z[end-4:end] for z in string.(df[:, :data])], df[:, :Acc],\n        group = string.(df[:, :method]), legend = :outerbottomright,\n        size = (1600, 800),\n        xlab = \"signal strength\", ylab = \"accuracy\",\n        title = \"Gaussian (n = 1000, p = 2000)\")","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"Also the ratio of BSS/TSS","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"groupedboxplot([z[end-4:end] for z in string.(df[:, :data])], df[:, \"BSS/TSS\"],\n        group = string.(df[:, :method]), legend = :outerbottomright,\n        size = (1600, 800),\n        xlab = \"signal strength\", ylab = \"BSS/TSS\",\n        title = \"Gaussian (n = 1000, p = 2000)\")","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"And the running time","category":"page"},{"location":"benchmarks/","page":"Benchmarks","title":"Benchmarks","text":"groupedboxplot([z[end-4:end] for z in string.(df[:, :data])], df[:, \"Time\"],\n        group = string.(df[:, :method]), legend = :outerbottomright,\n        size = (1600, 800),\n        xlab = \"signal strength\", ylab = \"Time\",\n        title = \"Gaussian (n = 1000, p = 2000)\")","category":"page"},{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Modules = [KmeansBenchmarks]\nOrder = [:type, :function]","category":"page"},{"location":"#Kmeans-Benchmarks","page":"Home","title":"Kmeans Benchmarks","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Clustering is a cornerstone of unsupervised machine learning, with the k-means algorithm standing as one of the most widely used methods for partitioning data into coherent groups. Its simplicity, interpretability, and adaptability have made it a staple in fields ranging from customer segmentation to bioinformatics. However, the performance and results of k-means can vary significantly depending on the implementation choices made by practitioners, including the software ecosystem (e.g., R, Julia, Python), the algorithmic variants employed (e.g., Lloyd’s algorithm, Hartigan-Wong, or scalable approximations like Mini-Batch k-means), and the initialization strategies (e.g., random seeding, k-means++, or density-based initialization). These choices impact not only computational efficiency but also the quality and stability of the resulting clusters.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This project seeks to systematically benchmark and compare k-means implementations across different frameworks—focusing on R and Julia as representative languages for statistical computing and high-performance numerical analysis, respectively—while also evaluating the interplay between initialization methods and algorithmic variants. R, with its rich ecosystem of packages (e.g., stats, ClusterR), offers user-friendly tools optimized for statistical rigor, whereas Julia (particularly the package Clustering), leveraging its just-in-time (JIT) compilation and parallel computing capabilities, promises faster execution for large datasets. Beyond software comparisons, the study will assess how initialization techniques (e.g., naive random centroids vs. sophisticated seeding) influence convergence rates, cluster quality metrics (e.g., silhouette score, within-cluster sum of squares), and sensitivity to local optima.","category":"page"},{"location":"","page":"Home","title":"Home","text":"By quantifying trade-offs between computational speed, scalability, and cluster accuracy, this work aims to provide actionable insights for researchers and practitioners in selecting optimal k-means configurations tailored to their data size, dimensionality, and domain requirements. The findings will contribute to a deeper understanding of how algorithmic choices and software ecosystems shape the practical utility of this foundational clustering method.","category":"page"}]
}
